# Reinforcement Learning in Machine Learning

This repository contains implementations of **Upper Confidence Bound (UCB)** and **Thompson Sampling**, two reinforcement learning algorithms designed to solve the **Multi-Armed Bandit Problem**.  
Both models are applied to the **Ads CTR Optimization Dataset** to determine which advertisement yields the best click-through rate.

---

## ğŸ“ Project Structure

```bash
REINFORCEMENT LEARNING
â”‚
â”œâ”€â”€ .vscode/
â”‚
â”œâ”€â”€ Ads_CTR_Optimisation.csv
â”‚
â”œâ”€â”€ Upper Confidence Bound (UCB)
â”‚ â”œâ”€â”€ upper_confidence_bound.ipynb
â”‚ â””â”€â”€ upper_confidence_bound.py
â”‚
â””â”€â”€ Thompson Sampling
â”œâ”€â”€ thompson_sampling.ipynb
â””â”€â”€ thompson_sampling.py
```


---

## ğŸ“Š Dataset

**Ads_CTR_Optimisation.csv** simulates user interactions with multiple ads by providing binary outcomes representing clicks (1) or no clicks (0).  
The task is to identify which ad performs best with minimal exploration cost.

---

## ğŸ§  Algorithms Used

| Algorithm | Purpose | Key Concept |
|-----------|---------|-------------|
| Upper Confidence Bound (UCB) | Balances exploration and exploitation using confidence intervals | Uses count of selections + average reward |
| Thompson Sampling | Probabilistic method for reward prediction and decision-making | Beta distribution for sampling best action |

---

## ğŸš€ Tools & Technologies

- Python  
- NumPy  
- Pandas  
- Matplotlib  

---

## ğŸ“ˆ Output Highlights

- Ad selection patterns over time  
- Comparative performance visualization  
- Optimized reward calculation for real decision systems  

---

## ğŸ”— Future Enhancements

- Add epsilon-greedy reinforcement strategy  
- Add reward comparison dashboard  
- Extend dataset for real-world CTR cases  

---

## ğŸ§‘â€ğŸ’» Author

Created as part of machine learning project development and reinforcement learning practice.

---

### â­ If this repository helps you, feel free to star it.
